{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-agent Test\n",
    "\n",
    "LLM-based Text Extractor\n",
    "- Fetch & Store Data in Graph Database (`neo4j`)\n",
    "\n",
    "\n",
    "\n",
    "Since 2025\n",
    "\n",
    "v. 0.2.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 README.pdf files\n",
      "Loaded data from rag/clark_doc\\ncaec\\Computer and NW Security - Undergrad\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Computer Security\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\CyberSkills2Work - Incident Response (DSU-009)\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Digital Forensics\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Network Defense\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Operating System Hardening\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Privacy\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Programming\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Secure Software Development\\README.pdf into Neo4j\n",
      "Loaded data from rag/clark_doc\\ncaec\\Software Security\\README.pdf into Neo4j\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from neo4j import GraphDatabase\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "NEO4J_URI = os.environ[\"NEO4J_URI\"]\n",
    "NEO4J_USERNAME = os.environ[\"NEO4J_USERNAME\"]\n",
    "NEO4J_PASSWORD = os.environ[\"NEO4J_PASSWORD\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Base directory containing the CLARK library\n",
    "CLARK_BASE_DIR = \"rag/clark_doc\"\n",
    "\n",
    "# Pydantic model for course data\n",
    "class CourseData(BaseModel):\n",
    "    course_name: str\n",
    "    collection_name: str\n",
    "    updated_time: Optional[str] = None\n",
    "    contributors: Optional[List[str]] = None\n",
    "    academic_levels: Optional[List[str]] = None\n",
    "    topic: Optional[str] = None\n",
    "    url_link: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    outcomes: Optional[List[str]] = None\n",
    "    alignment: Optional[List[str]] = None\n",
    "\n",
    "# Neo4j driver setup\n",
    "class Neo4jDriver:\n",
    "    def __init__(self, uri: str, username: str, password: str):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def create_course(self, course_data: CourseData):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\n",
    "                \"\"\"\n",
    "                MERGE (c:Course {name: $course_name})\n",
    "                SET c.updated_time = $updated_time,\n",
    "                    c.url_link = $url_link,\n",
    "                    c.description = $description\n",
    "                WITH c\n",
    "                MERGE (col:Collection {name: $collection_name})\n",
    "                MERGE (c)-[:BELONGS_TO]->(col)\n",
    "                \"\"\",\n",
    "                course_name=course_data.course_name,\n",
    "                collection_name=course_data.collection_name,\n",
    "                updated_time=course_data.updated_time,\n",
    "                url_link=course_data.url_link,\n",
    "                description=course_data.description,\n",
    "            )\n",
    "            if course_data.contributors:\n",
    "                for contributor in course_data.contributors:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (p:Contributor {name: $contributor})\n",
    "                        MERGE (c:Course {name: $course_name})\n",
    "                        MERGE (p)-[:CONTRIBUTED_TO]->(c)\n",
    "                        \"\"\",\n",
    "                        contributor=contributor,\n",
    "                        course_name=course_data.course_name,\n",
    "                    )\n",
    "            if course_data.academic_levels:\n",
    "                for level in course_data.academic_levels:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (l:AcademicLevel {name: $level})\n",
    "                        MERGE (c:Course {name: $course_name})\n",
    "                        MERGE (c)-[:TARGETS]->(l)\n",
    "                        \"\"\",\n",
    "                        level=level,\n",
    "                        course_name=course_data.course_name,\n",
    "                    )\n",
    "            if course_data.topic:\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (t:Topic {name: $topic})\n",
    "                    MERGE (c:Course {name: $course_name})\n",
    "                    MERGE (c)-[:COVERS]->(t)\n",
    "                    \"\"\",\n",
    "                    topic=course_data.topic,\n",
    "                    course_name=course_data.course_name,\n",
    "                )\n",
    "            if course_data.outcomes:\n",
    "                for outcome in course_data.outcomes:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (o:Outcome {description: $outcome})\n",
    "                        MERGE (c:Course {name: $course_name})\n",
    "                        MERGE (c)-[:ACHIEVES]->(o)\n",
    "                        \"\"\",\n",
    "                        outcome=outcome,\n",
    "                        course_name=course_data.course_name,\n",
    "                    )\n",
    "            if course_data.alignment:\n",
    "                for align in course_data.alignment:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (a:Alignment {name: $align})\n",
    "                        MERGE (c:Course {name: $course_name})\n",
    "                        MERGE (c)-[:ALIGNS_WITH]->(a)\n",
    "                        \"\"\",\n",
    "                        align=align,\n",
    "                        course_name=course_data.course_name,\n",
    "                    )\n",
    "\n",
    "# LLM setup\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def clean_llm_response(response: str) -> str:\n",
    "    \"\"\"Remove Markdown code block markers from LLM response.\"\"\"\n",
    "    # Strip ```json and ``` markers, including optional whitespace\n",
    "    cleaned = response.strip()\n",
    "    if cleaned.startswith(\"```json\"):\n",
    "        cleaned = cleaned[len(\"```json\"):].strip()\n",
    "    if cleaned.endswith(\"```\"):\n",
    "        cleaned = cleaned[:-len(\"```\")].strip()\n",
    "    # Also handle plain ``` if used without 'json'\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        cleaned = cleaned[len(\"```\"):].strip()\n",
    "    return cleaned\n",
    "\n",
    "def extract_data_from_readme(pdf_path: str) -> CourseData:\n",
    "    \"\"\"Extract structured data from a README.pdf using LLM.\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "    # Extract path-based metadata as fallback\n",
    "    parts = pdf_path.split(os.sep)\n",
    "    if len(parts) >= 3:\n",
    "        collection_name = parts[-3]\n",
    "        course_name = parts[-2]\n",
    "    else:\n",
    "        collection_name = \"unknown_collection\"\n",
    "        course_name = \"unknown_course\"\n",
    "\n",
    "    # LLM prompt with strict JSON instructions\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert data extractor. From the following README text, extract these fields into a valid JSON object:\n",
    "    - course_name (string)\n",
    "    - collection_name (string)\n",
    "    - updated_time (string or null)\n",
    "    - contributors (list of strings)\n",
    "    - academic_levels (list of strings)\n",
    "    - topic (string or null)\n",
    "    - url_link (string or null)\n",
    "    - description (string or null)\n",
    "    - outcomes (list of strings)\n",
    "    - alignment (list of strings)\n",
    "\n",
    "    Rules:\n",
    "    - Return ONLY a valid JSON string, no additional text or explanations.\n",
    "    - Use null for missing single-value fields (e.g., updated_time).\n",
    "    - Use empty lists for missing list fields (e.g., contributors).\n",
    "    - For multi-line sections (e.g., Description, Outcomes), concatenate or list items as appropriate.\n",
    "    - Handle multi-page content (e.g., Alignment) by combining relevant lines.\n",
    "\n",
    "    Text:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    cleaned_response = clean_llm_response(response.content)\n",
    "    \n",
    "    try:\n",
    "        extracted_data = json.loads(cleaned_response)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing LLM response for {pdf_path}: {e}\")\n",
    "        print(f\"Cleaned LLM response: {cleaned_response}\")\n",
    "        # Fallback to minimal data\n",
    "        extracted_data = {\n",
    "            \"course_name\": course_name,\n",
    "            \"collection_name\": collection_name,\n",
    "            \"updated_time\": None,\n",
    "            \"contributors\": [],\n",
    "            \"academic_levels\": [],\n",
    "            \"topic\": None,\n",
    "            \"url_link\": None,\n",
    "            \"description\": None,\n",
    "            \"outcomes\": [],\n",
    "            \"alignment\": [],\n",
    "        }\n",
    "\n",
    "    # Ensure all fields are present and typed correctly\n",
    "    data = {\n",
    "        \"course_name\": extracted_data.get(\"course_name\", course_name),\n",
    "        \"collection_name\": extracted_data.get(\"collection_name\", collection_name),\n",
    "        \"updated_time\": extracted_data.get(\"updated_time\"),\n",
    "        \"contributors\": extracted_data.get(\"contributors\", []) or [],\n",
    "        \"academic_levels\": extracted_data.get(\"academic_levels\", []) or [],\n",
    "        \"topic\": extracted_data.get(\"topic\"),\n",
    "        \"url_link\": extracted_data.get(\"url_link\"),\n",
    "        \"description\": extracted_data.get(\"description\"),\n",
    "        \"outcomes\": extracted_data.get(\"outcomes\", []) or [],\n",
    "        \"alignment\": extracted_data.get(\"alignment\", []) or [],\n",
    "    }\n",
    "\n",
    "    return CourseData(**data)\n",
    "\n",
    "def load_readme_files_into_neo4j(base_dir: str, neo4j_driver: Neo4jDriver):\n",
    "    readme_files = glob.glob(f\"{base_dir}/*/*/README.pdf\")\n",
    "    if not readme_files:\n",
    "        print(f\"No README.pdf files found in {base_dir}/*/*/README.pdf\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(readme_files)} README.pdf files\")\n",
    "    for readme_path in readme_files:\n",
    "        try:\n",
    "            course_data = extract_data_from_readme(readme_path)\n",
    "            neo4j_driver.create_course(course_data)\n",
    "            print(f\"Loaded data from {readme_path} into Neo4j\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {readme_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    neo4j_driver = Neo4jDriver(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "    load_readme_files_into_neo4j(CLARK_BASE_DIR, neo4j_driver)\n",
    "    neo4j_driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93f634be9a722f505c8b4f108732153585e535e7889bd0d25187ab344bf8cea5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
